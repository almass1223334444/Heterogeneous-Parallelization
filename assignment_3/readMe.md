1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В архитектуре CUDA используются несколько типов памяти:

Регистры — самая быстрая память, доступна только одному потоку.

Разделяемая память (Shared Memory) — очень быстрая память, общая для потоков одного блока.

Глобальная память (Global Memory) — большая по объёму, но самая медленная, доступна всем потокам и хосту.

Константная память (Constant Memory) — оптимизирована для чтения, эффективна при одинаковом доступе потоков.

Текстурная память (Texture Memory) — оптимизирована для пространственно локального доступа.

По скорости:
Регистры → Разделяемая → Константная/Текстурная → Глобальная память.

2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Разделяемая память ускоряет программу, когда:

данные многократно используются потоками одного блока;

требуется уменьшить количество обращений к глобальной памяти;

реализуются алгоритмы с локальной обработкой данных (например, свёртки, редукции).

Она особенно эффективна, когда потоки загружают данные из глобальной памяти один раз, а затем используют их из разделяемой памяти.

3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Производительность сильно зависит от коалесцированности доступа:

Коалесцированный доступ — потоки варпа обращаются к последовательным адресам памяти, что минимизирует количество транзакций.

Некоалесцированный доступ — обращения идут к разрозненным адресам, что увеличивает задержки.

Коалесцированный доступ позволяет эффективнее использовать пропускную способность памяти GPU.

4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Потому что:

задержки доступа к памяти различаются в десятки раз;

неэффективные обращения увеличивают количество транзакций;

кэширование может работать или не работать в зависимости от шаблона доступа.

Даже при одинаковых вычислениях узким местом часто становится память, а не арифметика.

5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока влияет на:

количество активных варпов (occupancy);

использование регистров и разделяемой памяти;

способность GPU скрывать задержки памяти.

Слишком маленькие блоки недоиспользуют GPU, слишком большие могут ограничить количество активных блоков.
Часто оптимальный размер — 128–256 потоков на блок.

6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

Варп — это группа из 32 потоков, выполняющихся одновременно по модели SIMD.

Важно учитывать варпы, потому что:

ветвления внутри варпа приводят к дивергенции;

некратное 32 количество потоков снижает эффективность;

доступ к памяти организован на уровне варпа.

Оптимальный код минимизирует дивергенцию и учитывает структуру варпов.

7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

Основные факторы:

архитектура GPU;

объём регистров и разделяемой памяти;

характер доступа к памяти;

количество вычислений на поток;

размер обрабатываемых данных.

Цель — обеспечить высокую загрузку GPU и эффективное использование памяти.

8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Потому что:

GPU гораздо быстрее выполняет вычисления, чем обращается к памяти;

неоптимальный доступ к памяти приводит к простоям вычислительных блоков;

улучшение доступа к памяти часто даёт больший прирост производительности, чем изменение алгоритма.

Поэтому оптимизация обычно начинается с:

анализа доступа к памяти;

коалесцирования;

использования разделяемой памяти;

только затем — изменения алгоритма.

Краткий вывод:

Эффективность CUDA-программ в первую очередь определяется работой с памятью, а не количеством операций. Понимание архитектуры GPU и правильный выбор конфигурации потоков позволяют значительно повысить производительность.