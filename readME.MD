==========================================1 вопрос=====================================================
1. В чём отличие динамического массива от статического массива в языке C++?

Статический массив: размер известен на этапе компиляции, память выделяется в стеке. Пример:

int arr[100];  // размер фиксирован 100


Динамический массив: размер задаётся во время выполнения, память выделяется в куче, управляется вручную через new/delete. Пример:

int* arr = new int[n];  // n вычисляется во время работы программы


Главное отличие: динамический массив гибкий по размеру, но требует явного освобождения памяти.

==========================================2 вопрос=====================================================

2. Что такое указатель и зачем он используется при работе с динамической памятью?

Указатель — переменная, которая хранит адрес другой переменной или блока памяти.

При работе с динамическими массивами:

Выделяем память через new → получаем адрес блока памяти

Сохраняем его в указателе, чтобы обращаться к элементам массива

Позволяет работать с массивами произвольного размера во время выполнения.

Пример:

int* array = new int[100];  // указатель array хранит адрес блока из 100 int

==========================================3 вопрос=====================================================

3. Почему важно корректно освобождать память после использования динамических массивов?

Динамическая память выделяется в куче.

Если её не освободить (delete[]), возникает утечка памяти:

Память остаётся занята

Программа потребляет больше ресурсов

Долгое время работы или многократные вызовы могут привести к ошибкам и падению программы.

==========================================4 вопрос=====================================================

4. В чём разница между последовательной и параллельной обработкой массива?

Последовательная обработка:

Один поток выполняет все операции по очереди.

Простая реализация, нет синхронизации.

Параллельная обработка:

Массив обрабатывается несколькими потоками одновременно.

Потоки делят работу на части, иногда требуется синхронизация (например, critical или reduction).

Преимущества параллельной обработки: может быть быстрее на многопроцессорных системах.

Недостатки: накладные расходы на создание потоков и синхронизацию.

==========================================5 вопрос=====================================================

5. Что делает директива #pragma omp parallel for?

Инструктирует компилятор распараллелить следующий цикл for.

Каждый поток выполняет часть итераций цикла.

Ускоряет выполнение на многоядерных процессорах.

Пример:

#pragma omp parallel for
for (int i = 0; i < n; i++) {
    array[i] = i * 2;
}

==========================================6 вопрос=====================================================

6. Для чего используется механизм reduction в OpenMP?

reduction позволяет корректно объединять результаты из нескольких потоков.

Например, при суммировании элементов массива:

Каждый поток считает локальную сумму

В конце локальные суммы суммируются автоматически в одну глобальную переменную

Без reduction была бы гонка данных (несколько потоков одновременно пишут в одну переменную).

Пример:

long long sum = 0;
#pragma omp parallel for reduction(+:sum)
for (int i = 0; i < n; i++) {
    sum += array[i];
}

==========================================7 вопрос=====================================================

7. Почему при параллельном вычислении суммы необходимо использовать reduction, а не обычную переменную?

Если использовать обычную переменную:

Несколько потоков одновременно пишут в неё → гонка данных

Результат будет неправильным

reduction создаёт локальные копии переменной для каждого потока и аккуратно объединяет их в конце → корректный результат

==========================================8 вопрос=====================================================

8. Какие факторы могут привести к тому, что параллельная версия программы будет работать медленнее последовательной?

Накладные расходы OpenMP:

Создание и завершение потоков

Распределение работы между потоками

Синхронизация потоков:

Использование critical или других блокировок замедляет выполнение

Малый объём работы:

Если массив маленький, параллелизация не окупает накладные расходы

Конкуренция за кэш и память:

Потоки одновременно обращаются к одной области памяти → кэш-промахи

Неэффективное использование потоков:

Например, слишком много потоков на малое число итераций
